{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655aa229",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554dd8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea12c542bb7949979629336d8314d67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: C:\\Users\\herew\\anaconda3\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py 852 getcaller\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 404: Not Found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Set up your WandB configuration\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduler-comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m, entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_username\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Define a simple MLP model\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSimpleMLP\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1189\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1188\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m-> 1189\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m   1190\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:1170\u001b[0m, in \u001b[0;36minit\u001b[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[0;32m   1168\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[0;32m   1169\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1170\u001b[0m     run \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39minit()\n\u001b[0;32m   1171\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\wandb\\sdk\\wandb_init.py:785\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    783\u001b[0m         backend\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[0;32m    784\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[1;32m--> 785\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m run_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[1;31mCommError\u001b[0m: It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 404: Not Found)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import wandb\n",
    "\n",
    "# Set up your WandB configuration\n",
    "wandb.init(project=\"scheduler-comparison\", entity=\"your_username\")\n",
    "\n",
    "# Define a simple MLP model\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Set up data transformations and DataLoader\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
    "\n",
    "# Initialize two different models\n",
    "model_cosine = SimpleMLP()\n",
    "model_step = SimpleMLP()\n",
    "\n",
    "# Define loss function and optimizers for both models\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_cosine = optim.SGD(model_cosine.parameters(), lr=0.1)\n",
    "optimizer_step = optim.SGD(model_step.parameters(), lr=0.1)\n",
    "\n",
    "# Set up the learning rate schedulers\n",
    "# Cosine Annealing LR scheduler\n",
    "cosine_scheduler = lr_scheduler.CosineAnnealingLR(optimizer_cosine, T_max=5)\n",
    "# Step LR scheduler\n",
    "step_scheduler = lr_scheduler.StepLR(optimizer_step, step_size=10, gamma=0.5)\n",
    "\n",
    "# Training loop for the Cosine Annealing scheduler\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer_cosine.zero_grad()\n",
    "        outputs = model_cosine(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_cosine.step()\n",
    "\n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\"Cosine Loss\": loss.item(), \"Epoch\": epoch})\n",
    "\n",
    "    cosine_scheduler.step()\n",
    "\n",
    "# Training loop for the StepLR scheduler\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "        optimizer_step.zero_grad()\n",
    "        outputs = model_step(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer_step.step()\n",
    "\n",
    "        # Log metrics to WandB\n",
    "        wandb.log({\"Step Loss\": loss.item(), \"Epoch\": epoch})\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        step_scheduler.step()\n",
    "\n",
    "# Finish the WandB run\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1de1e982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\herew/.netrc\n"
     ]
    }
   ],
   "source": [
    "!wandb login e646c0d3811286ec78074864658c743c1cdf8651\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130e5dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
