{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37c3e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5ForConditionalGeneration, AdamW, AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c8d1ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Multi30k dataset\n",
    "# dataset = load_dataset(\"bentrevett/multi30k\", split=\"train[:10000]\")  # Load only a subset for demonstration\n",
    "dataset = load_dataset(\"bentrevett/multi30k\")  # Load only a subset for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25320ff4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 29000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1014\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['en', 'de'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091af4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['en', 'de'],\n",
       "    num_rows: 29000\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9316239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize T5 tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5422408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_data(example):\n",
    "#     source_text = example[\"en\"]\n",
    "#     target_text = example[\"de\"]\n",
    "#     tokenized_inputs = tokenizer(\n",
    "#         source_text,\n",
    "#         padding=\"max_length\",\n",
    "#         truncation=True,\n",
    "#         max_length=128,\n",
    "#         return_tensors=\"pt\"\n",
    "#     )\n",
    "#     tokenized_targets = tokenizer(\n",
    "#         target_text,\n",
    "#         padding=\"max_length\",\n",
    "#         truncation=True,\n",
    "#         max_length=128,\n",
    "#         return_tensors=\"pt\"\n",
    "#     )\n",
    "#     return {\n",
    "#         \"input_ids\": tokenized_inputs.input_ids.flatten(),\n",
    "#         \"attention_mask\": tokenized_inputs.attention_mask.flatten(),\n",
    "#         \"labels\": tokenized_targets.input_ids.flatten(),\n",
    "#         \"labels_attention_mask\": tokenized_targets.attention_mask.flatten(),\n",
    "#     }\n",
    "\n",
    "\n",
    "# def tokenize_data(example):\n",
    "#     source_text = example[\"en\"]\n",
    "#     target_text = example[\"de\"]\n",
    "#     tokenized_inputs = tokenizer(\n",
    "#         source_text,\n",
    "#         padding=\"max_length\",\n",
    "#         truncation=True,\n",
    "#         max_length=128,\n",
    "#         return_tensors=\"pt\"\n",
    "#     )\n",
    "#     tokenized_targets = tokenizer(\n",
    "#         target_text,\n",
    "#         padding=\"max_length\",\n",
    "#         truncation=True,\n",
    "#         max_length=128,\n",
    "#         return_tensors=\"pt\"\n",
    "#     )\n",
    "#     return {\n",
    "#         \"input_ids\": tokenized_inputs.input_ids[0],\n",
    "#         \"attention_mask\": tokenized_inputs.attention_mask[0],\n",
    "#         \"labels\": tokenized_targets.input_ids[0],\n",
    "#         \"labels_attention_mask\": tokenized_targets.attention_mask[0],\n",
    "#     }\n",
    "\n",
    "\n",
    "# Tokenize and preprocess data\n",
    "def tokenize_data(batch):\n",
    "    src_texts = batch[\"en\"]\n",
    "    tgt_texts = batch[\"de\"]\n",
    "    tokenized_batch = tokenizer.prepare_seq2seq_batch(src_texts, tgt_texts, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n",
    "    return {\n",
    "        \"input_ids\": tokenized_batch.input_ids,\n",
    "        \"attention_mask\": tokenized_batch.attention_mask,\n",
    "        \"labels\": tokenized_batch.labels,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4af8ff66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dfe909ef6d44839bfdb7fb2b18d2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1014 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3986: FutureWarning: \n",
      "`prepare_seq2seq_batch` is deprecated and will be removed in version 5 of HuggingFace Transformers. Use the regular\n",
      "`__call__` method to prepare your inputs and targets.\n",
      "\n",
      "Here is a short example:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, text_target=tgt_texts, ...)\n",
      "\n",
      "If you either need to use different keyword arguments for the source and target texts, you should do two calls like\n",
      "this:\n",
      "\n",
      "model_inputs = tokenizer(src_texts, ...)\n",
      "labels = tokenizer(text_target=tgt_texts, ...)\n",
      "model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
      "\n",
      "See the documentation of your specific tokenizer for more details on the specific arguments to the tokenizer of choice.\n",
      "For a more complete example, see the implementation of `prepare_seq2seq_batch`.\n",
      "\n",
      "  warnings.warn(formatted_warning, FutureWarning)\n",
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3860: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.map(tokenize_data, batched=True)\n",
    "train_dataloader = DataLoader(dataset['train'], batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "425a5a32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-5): 5 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseActDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): ReLU()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training loop\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c60fcad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 15.820640563964844\n",
      "Epoch 1, Loss: 16.644502639770508\n",
      "Epoch 1, Loss: 12.472295761108398\n",
      "Epoch 1, Loss: 10.575727462768555\n",
      "Epoch 1, Loss: 13.414263725280762\n",
      "Epoch 1, Loss: 11.630632400512695\n",
      "Epoch 1, Loss: 9.811060905456543\n",
      "Epoch 1, Loss: 8.01409912109375\n",
      "Epoch 1, Loss: 7.290450096130371\n",
      "Epoch 1, Loss: 6.96305513381958\n",
      "Epoch 1, Loss: 5.64630651473999\n",
      "Epoch 1, Loss: 4.715773582458496\n",
      "Epoch 1, Loss: 5.045876979827881\n",
      "Epoch 1, Loss: 5.344414234161377\n",
      "Epoch 1, Loss: 3.6341774463653564\n",
      "Epoch 1, Loss: 3.9242188930511475\n",
      "Epoch 1, Loss: 2.660752534866333\n",
      "Epoch 1, Loss: 2.435250997543335\n",
      "Epoch 1, Loss: 2.7774152755737305\n",
      "Epoch 1, Loss: 2.654569625854492\n",
      "Epoch 1, Loss: 2.1253368854522705\n",
      "Epoch 1, Loss: 2.2670328617095947\n",
      "Epoch 1, Loss: 2.0567479133605957\n",
      "Epoch 1, Loss: 1.770506501197815\n",
      "Epoch 1, Loss: 2.1777429580688477\n",
      "Epoch 1, Loss: 1.9934669733047485\n",
      "Epoch 1, Loss: 2.3370704650878906\n",
      "Epoch 1, Loss: 2.2311651706695557\n",
      "Epoch 1, Loss: 2.0362725257873535\n",
      "Epoch 1, Loss: 2.0557963848114014\n",
      "Epoch 1, Loss: 2.579617500305176\n",
      "Epoch 1, Loss: 2.0929627418518066\n",
      "Epoch 1, Loss: 2.4053268432617188\n",
      "Epoch 1, Loss: 1.8747788667678833\n",
      "Epoch 1, Loss: 2.214149236679077\n",
      "Epoch 1, Loss: 2.2971856594085693\n",
      "Epoch 1, Loss: 1.7814502716064453\n",
      "Epoch 1, Loss: 2.276519536972046\n",
      "Epoch 1, Loss: 1.9799038171768188\n",
      "Epoch 1, Loss: 2.05942702293396\n",
      "Epoch 1, Loss: 1.7619457244873047\n",
      "Epoch 1, Loss: 2.023449420928955\n",
      "Epoch 1, Loss: 2.027621269226074\n",
      "Epoch 1, Loss: 1.9999061822891235\n",
      "Epoch 1, Loss: 1.895102620124817\n",
      "Epoch 1, Loss: 1.7521551847457886\n",
      "Epoch 1, Loss: 1.6121833324432373\n",
      "Epoch 1, Loss: 2.3354053497314453\n",
      "Epoch 1, Loss: 1.6114306449890137\n",
      "Epoch 1, Loss: 1.9351067543029785\n",
      "Epoch 1, Loss: 1.6709774732589722\n",
      "Epoch 1, Loss: 2.078618288040161\n",
      "Epoch 1, Loss: 1.646594524383545\n",
      "Epoch 1, Loss: 1.6331093311309814\n",
      "Epoch 1, Loss: 2.0003535747528076\n",
      "Epoch 1, Loss: 1.6722583770751953\n",
      "Epoch 1, Loss: 1.5952730178833008\n",
      "Epoch 1, Loss: 2.306468963623047\n",
      "Epoch 1, Loss: 1.875407099723816\n",
      "Epoch 1, Loss: 1.874745488166809\n",
      "Epoch 1, Loss: 1.7236133813858032\n",
      "Epoch 1, Loss: 1.4785436391830444\n",
      "Epoch 1, Loss: 1.5977649688720703\n",
      "Epoch 1, Loss: 1.8117926120758057\n",
      "Epoch 1, Loss: 1.7175387144088745\n",
      "Epoch 1, Loss: 1.8868108987808228\n",
      "Epoch 1, Loss: 1.3981409072875977\n",
      "Epoch 1, Loss: 1.33368980884552\n",
      "Epoch 1, Loss: 1.611967921257019\n",
      "Epoch 1, Loss: 1.3774539232254028\n",
      "Epoch 1, Loss: 1.8279892206192017\n",
      "Epoch 1, Loss: 1.6044931411743164\n",
      "Epoch 1, Loss: 1.7411582469940186\n",
      "Epoch 1, Loss: 1.7107795476913452\n",
      "Epoch 1, Loss: 1.594151496887207\n",
      "Epoch 1, Loss: 1.7912023067474365\n",
      "Epoch 1, Loss: 1.6796146631240845\n",
      "Epoch 1, Loss: 1.4687159061431885\n",
      "Epoch 1, Loss: 1.5938911437988281\n",
      "Epoch 1, Loss: 1.708704948425293\n",
      "Epoch 1, Loss: 1.254869818687439\n",
      "Epoch 1, Loss: 1.3914644718170166\n",
      "Epoch 1, Loss: 1.5013071298599243\n",
      "Epoch 1, Loss: 1.506697177886963\n",
      "Epoch 1, Loss: 1.5185298919677734\n",
      "Epoch 1, Loss: 1.6609669923782349\n",
      "Epoch 1, Loss: 1.6513727903366089\n",
      "Epoch 1, Loss: 1.7723530530929565\n",
      "Epoch 1, Loss: 1.7677980661392212\n",
      "Epoch 1, Loss: 1.446305751800537\n",
      "Epoch 1, Loss: 1.4175114631652832\n",
      "Epoch 1, Loss: 1.9625424146652222\n",
      "Epoch 1, Loss: 1.6939420700073242\n",
      "Epoch 1, Loss: 1.3681979179382324\n",
      "Epoch 1, Loss: 1.6260697841644287\n",
      "Epoch 1, Loss: 1.2995260953903198\n",
      "Epoch 1, Loss: 1.7743570804595947\n",
      "Epoch 1, Loss: 1.5602374076843262\n",
      "Epoch 1, Loss: 1.8193767070770264\n",
      "Epoch 1, Loss: 1.9077268838882446\n",
      "Epoch 1, Loss: 1.3911921977996826\n",
      "Epoch 1, Loss: 1.369244933128357\n",
      "Epoch 1, Loss: 1.577149510383606\n",
      "Epoch 1, Loss: 1.280731439590454\n",
      "Epoch 1, Loss: 1.5020030736923218\n",
      "Epoch 1, Loss: 1.5395278930664062\n",
      "Epoch 1, Loss: 1.3400131464004517\n",
      "Epoch 1, Loss: 1.3651705980300903\n",
      "Epoch 1, Loss: 1.473738431930542\n",
      "Epoch 1, Loss: 1.524356722831726\n",
      "Epoch 1, Loss: 1.4536879062652588\n",
      "Epoch 1, Loss: 1.72157621383667\n",
      "Epoch 1, Loss: 1.3468012809753418\n",
      "Epoch 1, Loss: 1.6978434324264526\n",
      "Epoch 1, Loss: 1.3367230892181396\n",
      "Epoch 1, Loss: 1.4525811672210693\n",
      "Epoch 1, Loss: 1.3430347442626953\n",
      "Epoch 1, Loss: 1.5099563598632812\n",
      "Epoch 1, Loss: 1.8611469268798828\n",
      "Epoch 1, Loss: 1.3257853984832764\n",
      "Epoch 1, Loss: 1.2069028615951538\n",
      "Epoch 1, Loss: 2.269212484359741\n",
      "Epoch 1, Loss: 1.0461328029632568\n",
      "Epoch 1, Loss: 1.3157238960266113\n",
      "Epoch 1, Loss: 1.4119244813919067\n",
      "Epoch 1, Loss: 1.5790258646011353\n",
      "Epoch 1, Loss: 1.1144028902053833\n",
      "Epoch 1, Loss: 1.3467421531677246\n",
      "Epoch 1, Loss: 0.9782859086990356\n",
      "Epoch 1, Loss: 1.3809494972229004\n",
      "Epoch 1, Loss: 1.175808310508728\n",
      "Epoch 1, Loss: 1.6510412693023682\n",
      "Epoch 1, Loss: 1.4435851573944092\n",
      "Epoch 1, Loss: 1.5628962516784668\n",
      "Epoch 1, Loss: 1.4414124488830566\n",
      "Epoch 1, Loss: 1.405645489692688\n",
      "Epoch 1, Loss: 1.4415115118026733\n",
      "Epoch 1, Loss: 1.2101761102676392\n",
      "Epoch 1, Loss: 1.3572031259536743\n",
      "Epoch 1, Loss: 1.5273422002792358\n",
      "Epoch 1, Loss: 1.4381251335144043\n",
      "Epoch 1, Loss: 1.0755701065063477\n",
      "Epoch 1, Loss: 1.028233289718628\n",
      "Epoch 1, Loss: 1.1530535221099854\n",
      "Epoch 1, Loss: 1.182368516921997\n",
      "Epoch 1, Loss: 1.4856607913970947\n",
      "Epoch 1, Loss: 1.5022847652435303\n",
      "Epoch 1, Loss: 1.405968189239502\n",
      "Epoch 1, Loss: 1.194807767868042\n",
      "Epoch 1, Loss: 1.5206910371780396\n",
      "Epoch 1, Loss: 1.1052091121673584\n",
      "Epoch 1, Loss: 1.695559024810791\n",
      "Epoch 1, Loss: 1.2757859230041504\n",
      "Epoch 1, Loss: 1.279254674911499\n",
      "Epoch 1, Loss: 1.3054085969924927\n",
      "Epoch 1, Loss: 1.3717275857925415\n",
      "Epoch 1, Loss: 1.4160953760147095\n",
      "Epoch 1, Loss: 1.501981258392334\n",
      "Epoch 1, Loss: 1.1383947134017944\n",
      "Epoch 1, Loss: 1.78129243850708\n",
      "Epoch 1, Loss: 1.253867268562317\n",
      "Epoch 1, Loss: 1.3534554243087769\n",
      "Epoch 1, Loss: 1.192797303199768\n",
      "Epoch 1, Loss: 1.0799810886383057\n",
      "Epoch 1, Loss: 1.353625774383545\n",
      "Epoch 1, Loss: 1.7073025703430176\n",
      "Epoch 1, Loss: 1.2223610877990723\n",
      "Epoch 1, Loss: 1.3980317115783691\n",
      "Epoch 1, Loss: 1.2239675521850586\n",
      "Epoch 1, Loss: 1.2286031246185303\n",
      "Epoch 1, Loss: 1.01968252658844\n",
      "Epoch 1, Loss: 1.271825909614563\n",
      "Epoch 1, Loss: 1.2815278768539429\n",
      "Epoch 1, Loss: 1.6542813777923584\n",
      "Epoch 1, Loss: 1.4968100786209106\n",
      "Epoch 1, Loss: 1.3967012166976929\n",
      "Epoch 1, Loss: 1.412759780883789\n",
      "Epoch 1, Loss: 1.3636512756347656\n",
      "Epoch 1, Loss: 1.2792422771453857\n",
      "Epoch 1, Loss: 1.5902304649353027\n",
      "Epoch 1, Loss: 1.3710200786590576\n",
      "Epoch 1, Loss: 1.1692440509796143\n",
      "Epoch 1, Loss: 1.0400292873382568\n",
      "Epoch 1, Loss: 1.478542685508728\n",
      "Epoch 1, Loss: 1.0883407592773438\n",
      "Epoch 1, Loss: 1.2147457599639893\n",
      "Epoch 1, Loss: 1.2958602905273438\n",
      "Epoch 1, Loss: 1.347251296043396\n",
      "Epoch 1, Loss: 1.2123888731002808\n",
      "Epoch 1, Loss: 1.0822041034698486\n",
      "Epoch 1, Loss: 1.1882718801498413\n",
      "Epoch 1, Loss: 1.3024665117263794\n",
      "Epoch 1, Loss: 1.3363722562789917\n",
      "Epoch 1, Loss: 1.0499187707901\n",
      "Epoch 1, Loss: 1.268312931060791\n",
      "Epoch 1, Loss: 1.231283187866211\n",
      "Epoch 1, Loss: 1.3919847011566162\n",
      "Epoch 1, Loss: 1.2563107013702393\n",
      "Epoch 1, Loss: 1.4004533290863037\n",
      "Epoch 1, Loss: 1.4026761054992676\n",
      "Epoch 1, Loss: 1.7878069877624512\n",
      "Epoch 1, Loss: 1.1085647344589233\n",
      "Epoch 1, Loss: 1.1020039319992065\n",
      "Epoch 1, Loss: 1.1484990119934082\n",
      "Epoch 1, Loss: 1.226671576499939\n",
      "Epoch 1, Loss: 1.1201684474945068\n",
      "Epoch 1, Loss: 1.4523366689682007\n",
      "Epoch 1, Loss: 1.1545357704162598\n",
      "Epoch 1, Loss: 1.435549259185791\n",
      "Epoch 1, Loss: 1.116799235343933\n",
      "Epoch 1, Loss: 1.339695692062378\n",
      "Epoch 1, Loss: 1.1579629182815552\n",
      "Epoch 1, Loss: 1.269068717956543\n",
      "Epoch 1, Loss: 1.1784909963607788\n",
      "Epoch 1, Loss: 1.2051568031311035\n",
      "Epoch 1, Loss: 1.0954571962356567\n",
      "Epoch 1, Loss: 1.400578260421753\n",
      "Epoch 1, Loss: 1.110844612121582\n",
      "Epoch 1, Loss: 1.5664094686508179\n",
      "Epoch 1, Loss: 1.3044819831848145\n",
      "Epoch 1, Loss: 1.0644527673721313\n",
      "Epoch 1, Loss: 1.075918436050415\n",
      "Epoch 1, Loss: 0.9185053706169128\n",
      "Epoch 1, Loss: 1.4939942359924316\n",
      "Epoch 1, Loss: 1.2204350233078003\n",
      "Epoch 1, Loss: 1.3347935676574707\n",
      "Epoch 1, Loss: 1.230194330215454\n",
      "Epoch 1, Loss: 1.0752766132354736\n",
      "Epoch 1, Loss: 1.0957273244857788\n",
      "Epoch 1, Loss: 1.209761619567871\n",
      "Epoch 1, Loss: 1.2603185176849365\n",
      "Epoch 1, Loss: 1.2121548652648926\n",
      "Epoch 1, Loss: 1.1719027757644653\n",
      "Epoch 1, Loss: 1.4138715267181396\n",
      "Epoch 1, Loss: 1.218156099319458\n",
      "Epoch 1, Loss: 1.0987260341644287\n",
      "Epoch 1, Loss: 1.3923977613449097\n",
      "Epoch 1, Loss: 1.2828658819198608\n",
      "Epoch 1, Loss: 1.3062927722930908\n",
      "Epoch 1, Loss: 1.3305280208587646\n",
      "Epoch 1, Loss: 1.1952073574066162\n",
      "Epoch 1, Loss: 1.2730644941329956\n",
      "Epoch 1, Loss: 1.2718772888183594\n",
      "Epoch 1, Loss: 1.1524091958999634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3288955688476562\n",
      "Epoch 1, Loss: 1.2222703695297241\n",
      "Epoch 1, Loss: 1.0391194820404053\n",
      "Epoch 1, Loss: 1.7210607528686523\n",
      "Epoch 1, Loss: 1.1088308095932007\n",
      "Epoch 1, Loss: 1.3022595643997192\n",
      "Epoch 1, Loss: 1.1816068887710571\n",
      "Epoch 1, Loss: 1.2047709226608276\n",
      "Epoch 1, Loss: 1.146044373512268\n",
      "Epoch 1, Loss: 1.5455447435379028\n",
      "Epoch 1, Loss: 1.1193480491638184\n",
      "Epoch 1, Loss: 0.9558967351913452\n",
      "Epoch 1, Loss: 1.0505965948104858\n",
      "Epoch 1, Loss: 1.3518226146697998\n",
      "Epoch 1, Loss: 1.2798446416854858\n",
      "Epoch 1, Loss: 1.1271202564239502\n",
      "Epoch 1, Loss: 1.3075603246688843\n",
      "Epoch 1, Loss: 1.2696930170059204\n",
      "Epoch 1, Loss: 1.1641111373901367\n",
      "Epoch 1, Loss: 1.424397349357605\n",
      "Epoch 1, Loss: 1.1116316318511963\n",
      "Epoch 1, Loss: 1.0655595064163208\n",
      "Epoch 1, Loss: 1.3450392484664917\n",
      "Epoch 1, Loss: 1.2386810779571533\n",
      "Epoch 1, Loss: 1.2947450876235962\n",
      "Epoch 1, Loss: 1.1056290864944458\n",
      "Epoch 1, Loss: 1.34517240524292\n",
      "Epoch 1, Loss: 1.1433374881744385\n",
      "Epoch 1, Loss: 1.1724401712417603\n",
      "Epoch 1, Loss: 1.2790343761444092\n",
      "Epoch 1, Loss: 1.1504064798355103\n",
      "Epoch 1, Loss: 1.2758971452713013\n",
      "Epoch 1, Loss: 1.0332424640655518\n",
      "Epoch 1, Loss: 1.4106580018997192\n",
      "Epoch 1, Loss: 1.2074055671691895\n",
      "Epoch 1, Loss: 1.3073749542236328\n",
      "Epoch 1, Loss: 1.092603087425232\n",
      "Epoch 1, Loss: 1.2729270458221436\n",
      "Epoch 1, Loss: 1.056588053703308\n",
      "Epoch 1, Loss: 1.3256345987319946\n",
      "Epoch 1, Loss: 1.0658175945281982\n",
      "Epoch 1, Loss: 0.9417695999145508\n",
      "Epoch 1, Loss: 1.0378268957138062\n",
      "Epoch 1, Loss: 1.1392182111740112\n",
      "Epoch 1, Loss: 1.105200171470642\n",
      "Epoch 1, Loss: 1.1779340505599976\n",
      "Epoch 1, Loss: 1.1420047283172607\n",
      "Epoch 1, Loss: 1.2195690870285034\n",
      "Epoch 1, Loss: 1.3081480264663696\n",
      "Epoch 1, Loss: 1.4060863256454468\n",
      "Epoch 1, Loss: 1.1557389497756958\n",
      "Epoch 1, Loss: 1.2549632787704468\n",
      "Epoch 1, Loss: 1.1765174865722656\n",
      "Epoch 1, Loss: 1.0657908916473389\n",
      "Epoch 1, Loss: 0.8877337574958801\n",
      "Epoch 1, Loss: 0.9222301840782166\n",
      "Epoch 1, Loss: 1.2595113515853882\n",
      "Epoch 1, Loss: 1.233540415763855\n",
      "Epoch 1, Loss: 1.0384886264801025\n",
      "Epoch 1, Loss: 0.9613563418388367\n",
      "Epoch 1, Loss: 1.307724118232727\n",
      "Epoch 1, Loss: 0.9766877293586731\n",
      "Epoch 1, Loss: 1.0424671173095703\n",
      "Epoch 1, Loss: 1.111032485961914\n",
      "Epoch 1, Loss: 1.0686113834381104\n",
      "Epoch 1, Loss: 1.183530330657959\n",
      "Epoch 1, Loss: 1.2565003633499146\n",
      "Epoch 1, Loss: 1.2079936265945435\n",
      "Epoch 1, Loss: 0.9758006930351257\n",
      "Epoch 1, Loss: 1.1412088871002197\n",
      "Epoch 1, Loss: 1.0916932821273804\n",
      "Epoch 1, Loss: 1.1211907863616943\n",
      "Epoch 1, Loss: 1.1577935218811035\n",
      "Epoch 1, Loss: 0.9877845644950867\n",
      "Epoch 1, Loss: 1.1090601682662964\n",
      "Epoch 1, Loss: 1.2341004610061646\n",
      "Epoch 1, Loss: 0.9650721549987793\n",
      "Epoch 1, Loss: 0.9343273043632507\n",
      "Epoch 1, Loss: 1.3051291704177856\n",
      "Epoch 1, Loss: 1.0260170698165894\n",
      "Epoch 1, Loss: 1.1273560523986816\n",
      "Epoch 1, Loss: 0.9982966780662537\n",
      "Epoch 1, Loss: 0.9189326763153076\n",
      "Epoch 1, Loss: 1.1895582675933838\n",
      "Epoch 1, Loss: 1.5386258363723755\n",
      "Epoch 1, Loss: 1.0131229162216187\n",
      "Epoch 1, Loss: 0.8827981352806091\n",
      "Epoch 1, Loss: 0.967653751373291\n",
      "Epoch 1, Loss: 0.8740860223770142\n",
      "Epoch 1, Loss: 1.2250725030899048\n",
      "Epoch 1, Loss: 1.0419310331344604\n",
      "Epoch 1, Loss: 1.0985102653503418\n",
      "Epoch 1, Loss: 1.0830602645874023\n",
      "Epoch 1, Loss: 1.2361719608306885\n",
      "Epoch 1, Loss: 1.2960460186004639\n",
      "Epoch 1, Loss: 1.0478030443191528\n",
      "Epoch 1, Loss: 1.3141124248504639\n",
      "Epoch 1, Loss: 1.22420334815979\n",
      "Epoch 1, Loss: 1.0501636266708374\n",
      "Epoch 1, Loss: 1.5501691102981567\n",
      "Epoch 1, Loss: 1.071818232536316\n",
      "Epoch 1, Loss: 1.3120750188827515\n",
      "Epoch 1, Loss: 1.2686399221420288\n",
      "Epoch 1, Loss: 1.3299537897109985\n",
      "Epoch 1, Loss: 1.2251722812652588\n",
      "Epoch 1, Loss: 0.8538359999656677\n",
      "Epoch 1, Loss: 1.055234670639038\n",
      "Epoch 1, Loss: 1.141310453414917\n",
      "Epoch 1, Loss: 0.9421258568763733\n",
      "Epoch 1, Loss: 1.3678479194641113\n",
      "Epoch 1, Loss: 1.0037811994552612\n",
      "Epoch 1, Loss: 1.148276686668396\n",
      "Epoch 1, Loss: 1.1655693054199219\n",
      "Epoch 1, Loss: 0.9133981466293335\n",
      "Epoch 1, Loss: 1.198955774307251\n",
      "Epoch 1, Loss: 1.28239905834198\n",
      "Epoch 1, Loss: 0.9306071996688843\n",
      "Epoch 1, Loss: 1.1155115365982056\n",
      "Epoch 1, Loss: 1.2770026922225952\n",
      "Epoch 1, Loss: 1.3948334455490112\n",
      "Epoch 1, Loss: 1.151466727256775\n",
      "Epoch 1, Loss: 1.147745132446289\n",
      "Epoch 1, Loss: 1.0267517566680908\n",
      "Epoch 1, Loss: 1.2692002058029175\n",
      "Epoch 1, Loss: 1.208797574043274\n",
      "Epoch 1, Loss: 1.1785261631011963\n",
      "Epoch 1, Loss: 0.9296063184738159\n",
      "Epoch 1, Loss: 1.221451759338379\n",
      "Epoch 1, Loss: 1.2797456979751587\n",
      "Epoch 1, Loss: 0.9177160859107971\n",
      "Epoch 1, Loss: 0.9260963797569275\n",
      "Epoch 1, Loss: 0.8503795862197876\n",
      "Epoch 1, Loss: 1.0072393417358398\n",
      "Epoch 1, Loss: 0.9453319311141968\n",
      "Epoch 1, Loss: 1.5874067544937134\n",
      "Epoch 1, Loss: 1.1926289796829224\n",
      "Epoch 1, Loss: 1.0698275566101074\n",
      "Epoch 1, Loss: 1.230019211769104\n",
      "Epoch 1, Loss: 1.1015939712524414\n",
      "Epoch 1, Loss: 1.0901052951812744\n",
      "Epoch 1, Loss: 1.3634995222091675\n",
      "Epoch 1, Loss: 1.216997742652893\n",
      "Epoch 1, Loss: 1.1160515546798706\n",
      "Epoch 1, Loss: 1.0308693647384644\n",
      "Epoch 1, Loss: 0.9645565152168274\n",
      "Epoch 1, Loss: 0.9106557369232178\n",
      "Epoch 1, Loss: 1.2014778852462769\n",
      "Epoch 1, Loss: 1.1001893281936646\n",
      "Epoch 1, Loss: 1.0475401878356934\n",
      "Epoch 1, Loss: 1.2287540435791016\n",
      "Epoch 1, Loss: 1.0374412536621094\n",
      "Epoch 1, Loss: 1.1673378944396973\n",
      "Epoch 1, Loss: 1.2692071199417114\n",
      "Epoch 1, Loss: 0.8560467958450317\n",
      "Epoch 1, Loss: 1.5288214683532715\n",
      "Epoch 1, Loss: 1.080063819885254\n",
      "Epoch 1, Loss: 0.9949705004692078\n",
      "Epoch 1, Loss: 1.1833261251449585\n",
      "Epoch 1, Loss: 1.2343530654907227\n",
      "Epoch 1, Loss: 0.8505381941795349\n",
      "Epoch 1, Loss: 1.0716158151626587\n",
      "Epoch 1, Loss: 1.811621069908142\n",
      "Epoch 1, Loss: 1.7726019620895386\n",
      "Epoch 1, Loss: 1.069380521774292\n",
      "Epoch 1, Loss: 1.0599759817123413\n",
      "Epoch 1, Loss: 1.000649094581604\n",
      "Epoch 1, Loss: 1.1130173206329346\n",
      "Epoch 1, Loss: 1.1524481773376465\n",
      "Epoch 1, Loss: 0.9177122712135315\n",
      "Epoch 1, Loss: 1.3406479358673096\n",
      "Epoch 1, Loss: 1.3450833559036255\n",
      "Epoch 1, Loss: 1.325001835823059\n",
      "Epoch 1, Loss: 1.1685444116592407\n",
      "Epoch 1, Loss: 1.2051396369934082\n",
      "Epoch 1, Loss: 1.1918343305587769\n",
      "Epoch 1, Loss: 0.9359734654426575\n",
      "Epoch 1, Loss: 1.0035278797149658\n",
      "Epoch 1, Loss: 0.9453674554824829\n",
      "Epoch 1, Loss: 1.0853288173675537\n",
      "Epoch 1, Loss: 1.323874831199646\n",
      "Epoch 1, Loss: 1.1298340559005737\n",
      "Epoch 1, Loss: 1.092437744140625\n",
      "Epoch 1, Loss: 1.0353975296020508\n",
      "Epoch 1, Loss: 1.2173453569412231\n",
      "Epoch 1, Loss: 1.6869691610336304\n",
      "Epoch 1, Loss: 1.0274394750595093\n",
      "Epoch 1, Loss: 1.0496426820755005\n",
      "Epoch 1, Loss: 0.7929889559745789\n",
      "Epoch 1, Loss: 1.0680969953536987\n",
      "Epoch 1, Loss: 1.3387283086776733\n",
      "Epoch 1, Loss: 0.8277626037597656\n",
      "Epoch 1, Loss: 1.1864397525787354\n",
      "Epoch 1, Loss: 1.0275518894195557\n",
      "Epoch 1, Loss: 1.2869558334350586\n",
      "Epoch 1, Loss: 1.1318755149841309\n",
      "Epoch 1, Loss: 1.2684153318405151\n",
      "Epoch 1, Loss: 0.9651069045066833\n",
      "Epoch 1, Loss: 1.1958454847335815\n",
      "Epoch 1, Loss: 1.0380505323410034\n",
      "Epoch 1, Loss: 1.128649353981018\n",
      "Epoch 1, Loss: 1.4464479684829712\n",
      "Epoch 1, Loss: 1.2005985975265503\n",
      "Epoch 1, Loss: 0.9757899045944214\n",
      "Epoch 1, Loss: 0.9340488910675049\n",
      "Epoch 1, Loss: 0.9811429381370544\n",
      "Epoch 1, Loss: 1.152506947517395\n",
      "Epoch 1, Loss: 0.8670670986175537\n",
      "Epoch 1, Loss: 1.2537273168563843\n",
      "Epoch 1, Loss: 1.5752151012420654\n",
      "Epoch 1, Loss: 1.1348756551742554\n",
      "Epoch 1, Loss: 1.086158037185669\n",
      "Epoch 1, Loss: 1.4777281284332275\n",
      "Epoch 1, Loss: 0.8923024535179138\n",
      "Epoch 1, Loss: 1.0398192405700684\n",
      "Epoch 1, Loss: 1.4382001161575317\n",
      "Epoch 1, Loss: 1.2886238098144531\n",
      "Epoch 1, Loss: 1.1398611068725586\n",
      "Epoch 1, Loss: 1.141116738319397\n",
      "Epoch 1, Loss: 1.3223342895507812\n",
      "Epoch 1, Loss: 1.0661792755126953\n",
      "Epoch 1, Loss: 1.042486548423767\n",
      "Epoch 1, Loss: 1.163150668144226\n",
      "Epoch 1, Loss: 1.1266520023345947\n",
      "Epoch 1, Loss: 1.1054737567901611\n",
      "Epoch 1, Loss: 1.20432710647583\n",
      "Epoch 1, Loss: 1.2826820611953735\n",
      "Epoch 1, Loss: 0.9865744709968567\n",
      "Epoch 1, Loss: 1.1448363065719604\n",
      "Epoch 1, Loss: 1.2961772680282593\n",
      "Epoch 1, Loss: 1.1544771194458008\n",
      "Epoch 1, Loss: 1.3084728717803955\n",
      "Epoch 1, Loss: 1.070015788078308\n",
      "Epoch 1, Loss: 1.350744605064392\n",
      "Epoch 1, Loss: 0.9384015202522278\n",
      "Epoch 1, Loss: 1.0467547178268433\n",
      "Epoch 1, Loss: 1.2823257446289062\n",
      "Epoch 1, Loss: 1.0529553890228271\n",
      "Epoch 1, Loss: 1.1272045373916626\n",
      "Epoch 1, Loss: 1.1034420728683472\n",
      "Epoch 1, Loss: 1.0453739166259766\n",
      "Epoch 1, Loss: 1.0486998558044434\n",
      "Epoch 1, Loss: 1.029595136642456\n",
      "Epoch 1, Loss: 0.9016159176826477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0925483703613281\n",
      "Epoch 1, Loss: 0.9925301671028137\n",
      "Epoch 1, Loss: 0.9065122008323669\n",
      "Epoch 1, Loss: 0.9817745685577393\n",
      "Epoch 1, Loss: 1.169045329093933\n",
      "Epoch 1, Loss: 0.8850644826889038\n",
      "Epoch 1, Loss: 1.0782181024551392\n",
      "Epoch 1, Loss: 1.0987434387207031\n",
      "Epoch 1, Loss: 1.2270654439926147\n",
      "Epoch 1, Loss: 0.8952287435531616\n",
      "Epoch 1, Loss: 1.123023509979248\n",
      "Epoch 1, Loss: 1.150870442390442\n",
      "Epoch 1, Loss: 1.1861785650253296\n",
      "Epoch 1, Loss: 0.8979470133781433\n",
      "Epoch 1, Loss: 1.0820505619049072\n",
      "Epoch 1, Loss: 1.2280534505844116\n",
      "Epoch 1, Loss: 0.9071065783500671\n",
      "Epoch 1, Loss: 0.9913535118103027\n",
      "Epoch 1, Loss: 1.0470881462097168\n",
      "Epoch 1, Loss: 1.2596890926361084\n",
      "Epoch 1, Loss: 1.0410308837890625\n",
      "Epoch 1, Loss: 1.0973645448684692\n",
      "Epoch 1, Loss: 1.2278499603271484\n",
      "Epoch 1, Loss: 0.8783794045448303\n",
      "Epoch 1, Loss: 1.0774587392807007\n",
      "Epoch 1, Loss: 1.177904725074768\n",
      "Epoch 1, Loss: 1.0632684230804443\n",
      "Epoch 1, Loss: 1.0536056756973267\n",
      "Epoch 1, Loss: 0.9760329723358154\n",
      "Epoch 1, Loss: 0.9231733679771423\n",
      "Epoch 1, Loss: 1.6807397603988647\n",
      "Epoch 1, Loss: 1.1771026849746704\n",
      "Epoch 1, Loss: 1.4313571453094482\n",
      "Epoch 1, Loss: 0.9351138472557068\n",
      "Epoch 1, Loss: 1.138366460800171\n",
      "Epoch 1, Loss: 1.4509356021881104\n",
      "Epoch 1, Loss: 0.9884812235832214\n",
      "Epoch 1, Loss: 0.999075710773468\n",
      "Epoch 1, Loss: 1.3176072835922241\n",
      "Epoch 1, Loss: 1.1437187194824219\n",
      "Epoch 1, Loss: 0.9652086496353149\n",
      "Epoch 1, Loss: 0.8399056792259216\n",
      "Epoch 1, Loss: 0.8638446927070618\n",
      "Epoch 1, Loss: 1.0952236652374268\n",
      "Epoch 1, Loss: 1.1395652294158936\n",
      "Epoch 1, Loss: 0.9933640956878662\n",
      "Epoch 1, Loss: 1.170426845550537\n",
      "Epoch 1, Loss: 1.16148042678833\n",
      "Epoch 1, Loss: 1.0122698545455933\n",
      "Epoch 1, Loss: 1.1821314096450806\n",
      "Epoch 1, Loss: 1.2752454280853271\n",
      "Epoch 1, Loss: 1.150711178779602\n",
      "Epoch 1, Loss: 1.1310673952102661\n",
      "Epoch 1, Loss: 1.3486580848693848\n",
      "Epoch 1, Loss: 1.1131422519683838\n",
      "Epoch 1, Loss: 0.9294981360435486\n",
      "Epoch 1, Loss: 1.293624997138977\n",
      "Epoch 1, Loss: 0.9996103048324585\n",
      "Epoch 1, Loss: 1.283738374710083\n",
      "Epoch 1, Loss: 0.8887661695480347\n",
      "Epoch 1, Loss: 1.2534031867980957\n",
      "Epoch 1, Loss: 0.8648977875709534\n",
      "Epoch 1, Loss: 1.1194541454315186\n",
      "Epoch 1, Loss: 1.0369538068771362\n",
      "Epoch 1, Loss: 1.0188913345336914\n",
      "Epoch 1, Loss: 1.2047463655471802\n",
      "Epoch 1, Loss: 1.131247878074646\n",
      "Epoch 1, Loss: 0.782099723815918\n",
      "Epoch 1, Loss: 1.0290309190750122\n",
      "Epoch 1, Loss: 1.059373378753662\n",
      "Epoch 1, Loss: 0.9857422113418579\n",
      "Epoch 1, Loss: 0.9413108229637146\n",
      "Epoch 1, Loss: 0.7898588180541992\n",
      "Epoch 1, Loss: 0.8352231979370117\n",
      "Epoch 1, Loss: 0.9360435605049133\n",
      "Epoch 1, Loss: 1.0183387994766235\n",
      "Epoch 1, Loss: 0.9860084056854248\n",
      "Epoch 1, Loss: 1.2699000835418701\n",
      "Epoch 1, Loss: 1.145417332649231\n",
      "Epoch 1, Loss: 0.8838354349136353\n",
      "Epoch 1, Loss: 0.8564507365226746\n",
      "Epoch 1, Loss: 0.8650912046432495\n",
      "Epoch 1, Loss: 0.9598783254623413\n",
      "Epoch 1, Loss: 0.6933027505874634\n",
      "Epoch 1, Loss: 1.278033971786499\n",
      "Epoch 1, Loss: 1.0032074451446533\n",
      "Epoch 1, Loss: 1.132575273513794\n",
      "Epoch 1, Loss: 0.9568620324134827\n",
      "Epoch 1, Loss: 0.8904029726982117\n",
      "Epoch 1, Loss: 1.0914819240570068\n",
      "Epoch 1, Loss: 0.9887979626655579\n",
      "Epoch 1, Loss: 0.954792320728302\n",
      "Epoch 1, Loss: 1.1257134675979614\n",
      "Epoch 1, Loss: 0.9610050320625305\n",
      "Epoch 1, Loss: 1.1190279722213745\n",
      "Epoch 1, Loss: 1.0507813692092896\n",
      "Epoch 1, Loss: 1.1399296522140503\n",
      "Epoch 1, Loss: 1.2935874462127686\n",
      "Epoch 1, Loss: 1.2637269496917725\n",
      "Epoch 1, Loss: 1.3315744400024414\n",
      "Epoch 1, Loss: 0.9846177101135254\n",
      "Epoch 1, Loss: 0.8506742119789124\n",
      "Epoch 1, Loss: 1.0984214544296265\n",
      "Epoch 1, Loss: 0.9435497522354126\n",
      "Epoch 1, Loss: 0.8605173826217651\n",
      "Epoch 1, Loss: 1.153889775276184\n",
      "Epoch 1, Loss: 1.0631624460220337\n",
      "Epoch 1, Loss: 1.096229076385498\n",
      "Epoch 1, Loss: 0.9357278943061829\n",
      "Epoch 1, Loss: 1.067673921585083\n",
      "Epoch 1, Loss: 1.1471203565597534\n",
      "Epoch 1, Loss: 0.9087436199188232\n",
      "Epoch 1, Loss: 1.186213493347168\n",
      "Epoch 1, Loss: 1.2012337446212769\n",
      "Epoch 1, Loss: 1.0793662071228027\n",
      "Epoch 1, Loss: 1.13423490524292\n",
      "Epoch 1, Loss: 1.0554035902023315\n",
      "Epoch 1, Loss: 1.1634544134140015\n",
      "Epoch 1, Loss: 0.8860034346580505\n",
      "Epoch 1, Loss: 0.9500120282173157\n",
      "Epoch 1, Loss: 1.0105526447296143\n",
      "Epoch 1, Loss: 1.175631046295166\n",
      "Epoch 1, Loss: 1.345715880393982\n",
      "Epoch 1, Loss: 0.9526399970054626\n",
      "Epoch 1, Loss: 0.8251837491989136\n",
      "Epoch 1, Loss: 0.7807512879371643\n",
      "Epoch 1, Loss: 1.3275097608566284\n",
      "Epoch 1, Loss: 0.8970621824264526\n",
      "Epoch 1, Loss: 1.2783864736557007\n",
      "Epoch 1, Loss: 0.9482123255729675\n",
      "Epoch 1, Loss: 0.9862121343612671\n",
      "Epoch 1, Loss: 1.5058929920196533\n",
      "Epoch 1, Loss: 0.9556415677070618\n",
      "Epoch 1, Loss: 1.385427713394165\n",
      "Epoch 1, Loss: 1.108574628829956\n",
      "Epoch 1, Loss: 0.9078356027603149\n",
      "Epoch 1, Loss: 1.0221267938613892\n",
      "Epoch 1, Loss: 1.0050524473190308\n",
      "Epoch 1, Loss: 1.1046955585479736\n",
      "Epoch 1, Loss: 0.8774074912071228\n",
      "Epoch 1, Loss: 0.9146043658256531\n",
      "Epoch 1, Loss: 1.0734684467315674\n",
      "Epoch 1, Loss: 1.0770974159240723\n",
      "Epoch 1, Loss: 0.9721174240112305\n",
      "Epoch 1, Loss: 0.894077479839325\n",
      "Epoch 1, Loss: 1.132003664970398\n",
      "Epoch 1, Loss: 0.9440920948982239\n",
      "Epoch 1, Loss: 0.929595947265625\n",
      "Epoch 1, Loss: 1.0603702068328857\n",
      "Epoch 1, Loss: 1.0992417335510254\n",
      "Epoch 1, Loss: 1.0064467191696167\n",
      "Epoch 1, Loss: 0.9735498428344727\n",
      "Epoch 1, Loss: 0.9481287598609924\n",
      "Epoch 1, Loss: 1.2617545127868652\n",
      "Epoch 1, Loss: 1.088832139968872\n",
      "Epoch 1, Loss: 1.2807258367538452\n",
      "Epoch 1, Loss: 0.7883870005607605\n",
      "Epoch 1, Loss: 1.0054658651351929\n",
      "Epoch 1, Loss: 0.9475125670433044\n",
      "Epoch 1, Loss: 1.140100359916687\n",
      "Epoch 1, Loss: 1.0548603534698486\n",
      "Epoch 1, Loss: 1.1750915050506592\n",
      "Epoch 1, Loss: 1.1420013904571533\n",
      "Epoch 1, Loss: 1.1755964756011963\n",
      "Epoch 1, Loss: 1.098212480545044\n",
      "Epoch 1, Loss: 0.9599874019622803\n",
      "Epoch 1, Loss: 0.9548456072807312\n",
      "Epoch 1, Loss: 1.1352077722549438\n",
      "Epoch 1, Loss: 0.9954601526260376\n",
      "Epoch 1, Loss: 0.7800450921058655\n",
      "Epoch 1, Loss: 1.0413953065872192\n",
      "Epoch 1, Loss: 0.9741666316986084\n",
      "Epoch 1, Loss: 0.8761889934539795\n",
      "Epoch 1, Loss: 1.1344660520553589\n",
      "Epoch 1, Loss: 1.3321397304534912\n",
      "Epoch 1, Loss: 1.2143774032592773\n",
      "Epoch 1, Loss: 1.5178323984146118\n",
      "Epoch 1, Loss: 1.1768274307250977\n",
      "Epoch 1, Loss: 0.9527756571769714\n",
      "Epoch 1, Loss: 0.9807916283607483\n",
      "Epoch 1, Loss: 0.9319519400596619\n",
      "Epoch 1, Loss: 1.327839970588684\n",
      "Epoch 1, Loss: 1.3236896991729736\n",
      "Epoch 1, Loss: 0.9356411695480347\n",
      "Epoch 1, Loss: 0.8632058501243591\n",
      "Epoch 1, Loss: 1.0047134160995483\n",
      "Epoch 1, Loss: 1.3359925746917725\n",
      "Epoch 1, Loss: 0.7873401641845703\n",
      "Epoch 1, Loss: 1.0584019422531128\n",
      "Epoch 1, Loss: 1.077890396118164\n",
      "Epoch 1, Loss: 0.7988627552986145\n",
      "Epoch 1, Loss: 1.1499894857406616\n",
      "Epoch 1, Loss: 1.1006790399551392\n",
      "Epoch 1, Loss: 0.9272172451019287\n",
      "Epoch 1, Loss: 0.8642295002937317\n",
      "Epoch 1, Loss: 1.1839009523391724\n",
      "Epoch 1, Loss: 1.0077730417251587\n",
      "Epoch 1, Loss: 0.8662407398223877\n",
      "Epoch 1, Loss: 0.988029956817627\n",
      "Epoch 1, Loss: 1.057735800743103\n",
      "Epoch 1, Loss: 0.7695368528366089\n",
      "Epoch 1, Loss: 1.081398606300354\n",
      "Epoch 1, Loss: 1.0281399488449097\n",
      "Epoch 1, Loss: 1.1101601123809814\n",
      "Epoch 1, Loss: 1.1901674270629883\n",
      "Epoch 1, Loss: 1.1843461990356445\n",
      "Epoch 1, Loss: 0.8803587555885315\n",
      "Epoch 1, Loss: 1.335291862487793\n",
      "Epoch 1, Loss: 0.8778553009033203\n",
      "Epoch 1, Loss: 1.168224811553955\n",
      "Epoch 1, Loss: 0.9306769967079163\n",
      "Epoch 1, Loss: 1.162463903427124\n",
      "Epoch 1, Loss: 1.1008867025375366\n",
      "Epoch 1, Loss: 1.0741472244262695\n",
      "Epoch 1, Loss: 0.9770166873931885\n",
      "Epoch 1, Loss: 1.2443878650665283\n",
      "Epoch 1, Loss: 0.9206278324127197\n",
      "Epoch 1, Loss: 1.1460195779800415\n",
      "Epoch 1, Loss: 1.1398777961730957\n",
      "Epoch 1, Loss: 1.0903539657592773\n",
      "Epoch 1, Loss: 0.9757436513900757\n",
      "Epoch 1, Loss: 1.1714229583740234\n",
      "Epoch 1, Loss: 0.8776853680610657\n",
      "Epoch 1, Loss: 0.830566942691803\n",
      "Epoch 1, Loss: 0.740485429763794\n",
      "Epoch 1, Loss: 0.953380286693573\n",
      "Epoch 1, Loss: 1.3771063089370728\n",
      "Epoch 1, Loss: 0.9805463552474976\n",
      "Epoch 1, Loss: 1.2179750204086304\n",
      "Epoch 1, Loss: 1.0510820150375366\n",
      "Epoch 1, Loss: 0.8767451643943787\n",
      "Epoch 1, Loss: 1.132980227470398\n",
      "Epoch 1, Loss: 0.8685720562934875\n",
      "Epoch 1, Loss: 1.0542595386505127\n",
      "Epoch 1, Loss: 0.8908581137657166\n",
      "Epoch 1, Loss: 0.9115713238716125\n",
      "Epoch 1, Loss: 1.2414021492004395\n",
      "Epoch 1, Loss: 0.9203794598579407\n",
      "Epoch 1, Loss: 0.8644799590110779\n",
      "Epoch 1, Loss: 0.8699430823326111\n",
      "Epoch 1, Loss: 1.0241703987121582\n",
      "Epoch 1, Loss: 1.014686942100525\n",
      "Epoch 1, Loss: 0.97187340259552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9348334074020386\n",
      "Epoch 1, Loss: 0.9938778877258301\n",
      "Epoch 1, Loss: 1.9604206085205078\n",
      "Epoch 1, Loss: 0.8776105046272278\n",
      "Epoch 1, Loss: 1.1393396854400635\n",
      "Epoch 1, Loss: 0.9990116357803345\n",
      "Epoch 1, Loss: 0.9174244403839111\n",
      "Epoch 1, Loss: 0.7713714838027954\n",
      "Epoch 1, Loss: 1.152059555053711\n",
      "Epoch 1, Loss: 1.4263888597488403\n",
      "Epoch 1, Loss: 1.2049397230148315\n",
      "Epoch 1, Loss: 1.120863914489746\n",
      "Epoch 1, Loss: 1.1336137056350708\n",
      "Epoch 1, Loss: 1.1913071870803833\n",
      "Epoch 1, Loss: 0.903164803981781\n",
      "Epoch 1, Loss: 0.8930233716964722\n",
      "Epoch 1, Loss: 1.2130651473999023\n",
      "Epoch 1, Loss: 0.8147178888320923\n",
      "Epoch 1, Loss: 0.8809313774108887\n",
      "Epoch 1, Loss: 1.0299816131591797\n",
      "Epoch 1, Loss: 1.3423792123794556\n",
      "Epoch 1, Loss: 0.9237436652183533\n",
      "Epoch 1, Loss: 0.8957298994064331\n",
      "Epoch 1, Loss: 1.0771201848983765\n",
      "Epoch 1, Loss: 1.0095648765563965\n",
      "Epoch 1, Loss: 1.0321826934814453\n",
      "Epoch 1, Loss: 0.7436906695365906\n",
      "Epoch 1, Loss: 1.4529914855957031\n",
      "Epoch 1, Loss: 1.379470944404602\n",
      "Epoch 1, Loss: 1.0071332454681396\n",
      "Epoch 1, Loss: 0.7007628083229065\n",
      "Epoch 1, Loss: 0.9875996112823486\n",
      "Epoch 1, Loss: 1.0289878845214844\n",
      "Epoch 1, Loss: 1.1176315546035767\n",
      "Epoch 1, Loss: 1.1718968152999878\n",
      "Epoch 1, Loss: 0.9417128562927246\n",
      "Epoch 1, Loss: 1.2380414009094238\n",
      "Epoch 1, Loss: 1.1703797578811646\n",
      "Epoch 1, Loss: 1.0159249305725098\n",
      "Epoch 1, Loss: 1.2693052291870117\n",
      "Epoch 1, Loss: 1.1342661380767822\n",
      "Epoch 1, Loss: 1.089741587638855\n",
      "Epoch 1, Loss: 1.091126799583435\n",
      "Epoch 1, Loss: 1.0414419174194336\n",
      "Epoch 1, Loss: 0.875205934047699\n",
      "Epoch 1, Loss: 1.032669186592102\n",
      "Epoch 1, Loss: 1.2417176961898804\n",
      "Epoch 1, Loss: 0.8611952662467957\n",
      "Epoch 1, Loss: 0.9256469011306763\n",
      "Epoch 1, Loss: 1.051639437675476\n",
      "Epoch 1, Loss: 1.1782100200653076\n",
      "Epoch 1, Loss: 1.0605896711349487\n",
      "Epoch 1, Loss: 1.1920076608657837\n",
      "Epoch 1, Loss: 0.9630030393600464\n",
      "Epoch 1, Loss: 1.1364727020263672\n",
      "Epoch 1, Loss: 0.8267090320587158\n",
      "Epoch 1, Loss: 0.9108996391296387\n",
      "Epoch 1, Loss: 0.8876532912254333\n",
      "Epoch 1, Loss: 1.1020808219909668\n",
      "Epoch 1, Loss: 1.0711439847946167\n",
      "Epoch 1, Loss: 1.141147255897522\n",
      "Epoch 1, Loss: 1.0134133100509644\n",
      "Epoch 1, Loss: 1.09591543674469\n",
      "Epoch 1, Loss: 1.1453272104263306\n",
      "Epoch 1, Loss: 0.9465641975402832\n",
      "Epoch 1, Loss: 1.000218391418457\n",
      "Epoch 1, Loss: 1.14621102809906\n",
      "Epoch 1, Loss: 0.741659939289093\n",
      "Epoch 1, Loss: 1.2370014190673828\n",
      "Epoch 1, Loss: 0.9603922963142395\n",
      "Epoch 1, Loss: 1.335426926612854\n",
      "Epoch 1, Loss: 1.176041841506958\n",
      "Epoch 1, Loss: 1.3244686126708984\n",
      "Epoch 1, Loss: 0.9593996405601501\n",
      "Epoch 1, Loss: 0.918412983417511\n",
      "Epoch 1, Loss: 0.9076848030090332\n",
      "Epoch 1, Loss: 1.4177803993225098\n",
      "Epoch 1, Loss: 0.9372934699058533\n",
      "Epoch 1, Loss: 1.2468081712722778\n",
      "Epoch 1, Loss: 0.978681206703186\n",
      "Epoch 1, Loss: 1.206300139427185\n",
      "Epoch 1, Loss: 1.032607078552246\n",
      "Epoch 1, Loss: 1.0019406080245972\n",
      "Epoch 1, Loss: 1.0596778392791748\n",
      "Epoch 1, Loss: 0.9267935752868652\n",
      "Epoch 1, Loss: 1.0086174011230469\n",
      "Epoch 1, Loss: 1.394566535949707\n",
      "Epoch 1, Loss: 1.1905039548873901\n",
      "Epoch 1, Loss: 0.8970974087715149\n",
      "Epoch 1, Loss: 1.0528533458709717\n",
      "Epoch 1, Loss: 1.0510804653167725\n",
      "Epoch 1, Loss: 1.0748462677001953\n",
      "Epoch 1, Loss: 1.016272783279419\n",
      "Epoch 1, Loss: 1.064826250076294\n",
      "Epoch 1, Loss: 0.9849560260772705\n",
      "Epoch 1, Loss: 1.1115390062332153\n",
      "Epoch 1, Loss: 0.9116954207420349\n",
      "Epoch 1, Loss: 1.0091053247451782\n",
      "Epoch 1, Loss: 0.8223667144775391\n",
      "Epoch 1, Loss: 0.910026490688324\n",
      "Epoch 1, Loss: 1.2445579767227173\n",
      "Epoch 1, Loss: 0.958135187625885\n",
      "Epoch 1, Loss: 1.0142326354980469\n",
      "Epoch 1, Loss: 1.2067328691482544\n",
      "Epoch 1, Loss: 1.0492582321166992\n",
      "Epoch 1, Loss: 1.0659894943237305\n",
      "Epoch 1, Loss: 0.8818018436431885\n",
      "Epoch 1, Loss: 1.068312406539917\n",
      "Epoch 1, Loss: 1.1284394264221191\n",
      "Epoch 1, Loss: 1.006286859512329\n",
      "Epoch 1, Loss: 0.9463990330696106\n",
      "Epoch 1, Loss: 0.9990320205688477\n",
      "Epoch 1, Loss: 0.9595019221305847\n",
      "Epoch 1, Loss: 1.2511637210845947\n",
      "Epoch 1, Loss: 1.0386887788772583\n",
      "Epoch 1, Loss: 0.901833713054657\n",
      "Epoch 1, Loss: 1.011306881904602\n",
      "Epoch 1, Loss: 1.1681149005889893\n",
      "Epoch 1, Loss: 1.120559573173523\n",
      "Epoch 1, Loss: 0.88421630859375\n",
      "Epoch 1, Loss: 1.13009774684906\n",
      "Epoch 1, Loss: 1.0532197952270508\n",
      "Epoch 1, Loss: 1.1195287704467773\n",
      "Epoch 1, Loss: 0.9891563653945923\n",
      "Epoch 1, Loss: 0.7941011190414429\n",
      "Epoch 1, Loss: 0.8975253105163574\n",
      "Epoch 1, Loss: 0.9514085054397583\n",
      "Epoch 1, Loss: 0.8509554862976074\n",
      "Epoch 1, Loss: 1.171095371246338\n",
      "Epoch 1, Loss: 1.013609528541565\n",
      "Epoch 1, Loss: 0.8642199635505676\n",
      "Epoch 1, Loss: 1.0175830125808716\n",
      "Epoch 1, Loss: 1.0027769804000854\n",
      "Epoch 1, Loss: 1.1241493225097656\n",
      "Epoch 1, Loss: 0.9314942955970764\n",
      "Epoch 1, Loss: 1.1374139785766602\n",
      "Epoch 1, Loss: 0.9937099814414978\n",
      "Epoch 1, Loss: 0.8585950136184692\n",
      "Epoch 1, Loss: 1.1588677167892456\n",
      "Epoch 1, Loss: 0.8797538876533508\n",
      "Epoch 1, Loss: 1.0159265995025635\n",
      "Epoch 1, Loss: 0.9028071761131287\n",
      "Epoch 1, Loss: 0.8873805999755859\n",
      "Epoch 1, Loss: 0.9697455167770386\n",
      "Epoch 1, Loss: 1.114831566810608\n",
      "Epoch 1, Loss: 1.1430882215499878\n",
      "Epoch 1, Loss: 1.075178623199463\n",
      "Epoch 1, Loss: 0.9850673079490662\n",
      "Epoch 1, Loss: 0.8246350884437561\n",
      "Epoch 1, Loss: 1.1113992929458618\n",
      "Epoch 1, Loss: 1.2126833200454712\n",
      "Epoch 1, Loss: 1.0600996017456055\n",
      "Epoch 1, Loss: 0.9305983781814575\n",
      "Epoch 1, Loss: 1.1280099153518677\n",
      "Epoch 1, Loss: 1.195410132408142\n",
      "Epoch 1, Loss: 0.9262407422065735\n",
      "Epoch 1, Loss: 0.9708403944969177\n",
      "Epoch 1, Loss: 1.362236499786377\n",
      "Epoch 1, Loss: 1.0438437461853027\n",
      "Epoch 1, Loss: 0.9981881380081177\n",
      "Epoch 1, Loss: 1.3196957111358643\n",
      "Epoch 1, Loss: 0.898346483707428\n",
      "Epoch 1, Loss: 0.8520604372024536\n",
      "Epoch 1, Loss: 1.258522629737854\n",
      "Epoch 1, Loss: 1.0491552352905273\n",
      "Epoch 1, Loss: 1.1033169031143188\n",
      "Epoch 1, Loss: 1.292249083518982\n",
      "Epoch 1, Loss: 1.003314733505249\n",
      "Epoch 1, Loss: 1.2580723762512207\n",
      "Epoch 1, Loss: 1.047497272491455\n",
      "Epoch 1, Loss: 0.7958284616470337\n",
      "Epoch 1, Loss: 0.9367699027061462\n",
      "Epoch 1, Loss: 1.0805832147598267\n",
      "Epoch 1, Loss: 1.1818454265594482\n",
      "Epoch 1, Loss: 0.859083354473114\n",
      "Epoch 1, Loss: 1.0988068580627441\n",
      "Epoch 1, Loss: 1.134304165840149\n",
      "Epoch 1, Loss: 1.1510770320892334\n",
      "Epoch 1, Loss: 1.043684482574463\n",
      "Epoch 1, Loss: 1.1413261890411377\n",
      "Epoch 1, Loss: 1.079671025276184\n",
      "Epoch 1, Loss: 0.8503403067588806\n",
      "Epoch 1, Loss: 1.051741361618042\n",
      "Epoch 1, Loss: 0.9683733582496643\n",
      "Epoch 1, Loss: 0.7427522540092468\n",
      "Epoch 1, Loss: 1.0259400606155396\n",
      "Epoch 1, Loss: 1.1186829805374146\n",
      "Epoch 1, Loss: 1.1480963230133057\n",
      "Epoch 1, Loss: 0.8680333495140076\n",
      "Epoch 1, Loss: 1.0730984210968018\n",
      "Epoch 1, Loss: 1.0682978630065918\n",
      "Epoch 1, Loss: 0.810598611831665\n",
      "Epoch 1, Loss: 1.1604633331298828\n",
      "Epoch 1, Loss: 0.9729580283164978\n",
      "Epoch 1, Loss: 0.9062714576721191\n",
      "Epoch 1, Loss: 0.9793753623962402\n",
      "Epoch 1, Loss: 1.3462600708007812\n",
      "Epoch 1, Loss: 1.2551590204238892\n",
      "Epoch 1, Loss: 1.2237495183944702\n",
      "Epoch 1, Loss: 1.1195343732833862\n",
      "Epoch 1, Loss: 1.191664695739746\n",
      "Epoch 1, Loss: 1.030876636505127\n",
      "Epoch 1, Loss: 1.1166326999664307\n",
      "Epoch 1, Loss: 1.2225263118743896\n",
      "Epoch 1, Loss: 0.742294430732727\n",
      "Epoch 1, Loss: 1.0215330123901367\n",
      "Epoch 1, Loss: 1.1035677194595337\n",
      "Epoch 1, Loss: 1.1376398801803589\n",
      "Epoch 1, Loss: 1.0290409326553345\n",
      "Epoch 1, Loss: 0.9426678419113159\n",
      "Epoch 1, Loss: 0.9075765013694763\n",
      "Epoch 1, Loss: 0.8265075087547302\n",
      "Epoch 1, Loss: 0.9537485837936401\n",
      "Epoch 1, Loss: 1.2363423109054565\n",
      "Epoch 1, Loss: 1.0585561990737915\n",
      "Epoch 1, Loss: 1.1081527471542358\n",
      "Epoch 1, Loss: 1.1144604682922363\n",
      "Epoch 1, Loss: 0.9305893182754517\n",
      "Epoch 1, Loss: 1.0187021493911743\n",
      "Epoch 1, Loss: 1.191809058189392\n",
      "Epoch 1, Loss: 1.0680737495422363\n",
      "Epoch 1, Loss: 1.0956284999847412\n",
      "Epoch 1, Loss: 1.0009788274765015\n",
      "Epoch 1, Loss: 0.9712032675743103\n",
      "Epoch 1, Loss: 0.8342331051826477\n",
      "Epoch 1, Loss: 1.2726845741271973\n",
      "Epoch 1, Loss: 1.1970571279525757\n",
      "Epoch 1, Loss: 1.103065848350525\n",
      "Epoch 1, Loss: 0.9569212794303894\n",
      "Epoch 1, Loss: 1.0393991470336914\n",
      "Epoch 1, Loss: 1.352445363998413\n",
      "Epoch 1, Loss: 0.9407076835632324\n",
      "Epoch 1, Loss: 0.8946446776390076\n",
      "Epoch 1, Loss: 1.2179062366485596\n",
      "Epoch 1, Loss: 0.8897982239723206\n",
      "Epoch 1, Loss: 0.9737475514411926\n",
      "Epoch 1, Loss: 1.0656585693359375\n",
      "Epoch 1, Loss: 0.9188399910926819\n",
      "Epoch 1, Loss: 1.1697611808776855\n",
      "Epoch 1, Loss: 1.0661805868148804\n",
      "Epoch 1, Loss: 0.798912763595581\n",
      "Epoch 1, Loss: 0.9357390403747559\n",
      "Epoch 1, Loss: 1.1188749074935913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9256994128227234\n",
      "Epoch 1, Loss: 1.169124960899353\n",
      "Epoch 1, Loss: 1.1519508361816406\n",
      "Epoch 1, Loss: 0.9163281917572021\n",
      "Epoch 1, Loss: 0.9894132018089294\n",
      "Epoch 1, Loss: 0.9285848140716553\n",
      "Epoch 1, Loss: 0.9802454113960266\n",
      "Epoch 1, Loss: 1.0638347864151\n",
      "Epoch 1, Loss: 1.1791871786117554\n",
      "Epoch 1, Loss: 0.9312562346458435\n",
      "Epoch 1, Loss: 0.9086233973503113\n",
      "Epoch 1, Loss: 1.0347466468811035\n",
      "Epoch 1, Loss: 0.9783806204795837\n",
      "Epoch 1, Loss: 1.0336073637008667\n",
      "Epoch 1, Loss: 1.0561054944992065\n",
      "Epoch 1, Loss: 1.0325379371643066\n",
      "Epoch 1, Loss: 1.0244206190109253\n",
      "Epoch 1, Loss: 1.0418925285339355\n",
      "Epoch 1, Loss: 0.9455490708351135\n",
      "Epoch 1, Loss: 1.1853142976760864\n",
      "Epoch 1, Loss: 1.035148024559021\n",
      "Epoch 1, Loss: 1.1702507734298706\n",
      "Epoch 1, Loss: 1.2606501579284668\n",
      "Epoch 1, Loss: 0.8065730333328247\n",
      "Epoch 1, Loss: 1.072683334350586\n",
      "Epoch 1, Loss: 0.9969582557678223\n",
      "Epoch 1, Loss: 1.145089864730835\n",
      "Epoch 1, Loss: 0.948080837726593\n",
      "Epoch 1, Loss: 1.0851714611053467\n",
      "Epoch 1, Loss: 0.9105268716812134\n",
      "Epoch 1, Loss: 1.2218515872955322\n",
      "Epoch 1, Loss: 1.079728126525879\n",
      "Epoch 1, Loss: 0.9011880159378052\n",
      "Epoch 1, Loss: 0.9116866588592529\n",
      "Epoch 1, Loss: 1.195887565612793\n",
      "Epoch 1, Loss: 0.8915367722511292\n",
      "Epoch 1, Loss: 0.9544552564620972\n",
      "Epoch 1, Loss: 1.0196175575256348\n",
      "Epoch 1, Loss: 0.9626269936561584\n",
      "Epoch 1, Loss: 1.2173645496368408\n",
      "Epoch 1, Loss: 1.1163902282714844\n",
      "Epoch 1, Loss: 1.2451221942901611\n",
      "Epoch 1, Loss: 1.0365231037139893\n",
      "Epoch 1, Loss: 0.9400502443313599\n",
      "Epoch 1, Loss: 1.150212049484253\n",
      "Epoch 1, Loss: 1.037758469581604\n",
      "Epoch 1, Loss: 1.138494849205017\n",
      "Epoch 1, Loss: 1.4398022890090942\n",
      "Epoch 1, Loss: 1.3788901567459106\n",
      "Epoch 1, Loss: 0.9735817909240723\n",
      "Epoch 1, Loss: 1.0745887756347656\n",
      "Epoch 1, Loss: 0.8317675590515137\n",
      "Epoch 1, Loss: 0.7435475587844849\n",
      "Epoch 1, Loss: 0.9315230250358582\n",
      "Epoch 1, Loss: 1.0791269540786743\n",
      "Epoch 1, Loss: 0.9474718570709229\n",
      "Epoch 1, Loss: 0.8704729080200195\n",
      "Epoch 1, Loss: 0.9562795162200928\n",
      "Epoch 1, Loss: 1.0416374206542969\n",
      "Epoch 1, Loss: 1.0596758127212524\n",
      "Epoch 1, Loss: 1.0509276390075684\n",
      "Epoch 1, Loss: 1.156378149986267\n",
      "Epoch 1, Loss: 0.9886196851730347\n",
      "Epoch 1, Loss: 1.0910943746566772\n",
      "Epoch 1, Loss: 1.1386713981628418\n",
      "Epoch 1, Loss: 0.9405738711357117\n",
      "Epoch 1, Loss: 1.1413776874542236\n",
      "Epoch 1, Loss: 1.1883447170257568\n",
      "Epoch 1, Loss: 0.9625300168991089\n",
      "Epoch 1, Loss: 0.8636142015457153\n",
      "Epoch 1, Loss: 1.071368932723999\n",
      "Epoch 1, Loss: 1.1296823024749756\n",
      "Epoch 1, Loss: 0.9095107316970825\n",
      "Epoch 1, Loss: 1.0181888341903687\n",
      "Epoch 1, Loss: 0.9453943371772766\n",
      "Epoch 1, Loss: 1.0681343078613281\n",
      "Epoch 1, Loss: 0.939050018787384\n",
      "Epoch 1, Loss: 0.9040067195892334\n",
      "Epoch 1, Loss: 0.9151448607444763\n",
      "Epoch 1, Loss: 0.9125480651855469\n",
      "Epoch 1, Loss: 1.3634244203567505\n",
      "Epoch 1, Loss: 0.9087865352630615\n",
      "Epoch 1, Loss: 1.1119756698608398\n",
      "Epoch 1, Loss: 0.9985066652297974\n",
      "Epoch 1, Loss: 0.9650554656982422\n",
      "Epoch 1, Loss: 1.086467981338501\n",
      "Epoch 1, Loss: 0.8542143106460571\n",
      "Epoch 1, Loss: 1.0241354703903198\n",
      "Epoch 1, Loss: 1.452669382095337\n",
      "Epoch 1, Loss: 0.9422115087509155\n",
      "Epoch 1, Loss: 1.0700641870498657\n",
      "Epoch 1, Loss: 1.1497302055358887\n",
      "Epoch 1, Loss: 1.1156336069107056\n",
      "Epoch 1, Loss: 0.8403878211975098\n",
      "Epoch 1, Loss: 0.8106096386909485\n",
      "Epoch 1, Loss: 1.4432085752487183\n",
      "Epoch 1, Loss: 0.8953999876976013\n",
      "Epoch 1, Loss: 0.9601835608482361\n",
      "Epoch 1, Loss: 1.0536702871322632\n",
      "Epoch 1, Loss: 0.932053804397583\n",
      "Epoch 1, Loss: 0.9820271730422974\n",
      "Epoch 1, Loss: 0.9679386615753174\n",
      "Epoch 1, Loss: 1.0412217378616333\n",
      "Epoch 1, Loss: 1.232291340827942\n",
      "Epoch 1, Loss: 1.0644066333770752\n",
      "Epoch 1, Loss: 1.2627705335617065\n",
      "Epoch 1, Loss: 1.2013206481933594\n",
      "Epoch 1, Loss: 0.9031955599784851\n",
      "Epoch 1, Loss: 0.9594787359237671\n",
      "Epoch 1, Loss: 0.991719663143158\n",
      "Epoch 1, Loss: 1.1740946769714355\n",
      "Epoch 1, Loss: 0.7447211742401123\n",
      "Epoch 1, Loss: 0.8618704080581665\n",
      "Epoch 1, Loss: 1.2990691661834717\n",
      "Epoch 1, Loss: 0.8377909660339355\n",
      "Epoch 1, Loss: 1.4060896635055542\n",
      "Epoch 1, Loss: 1.028555154800415\n",
      "Epoch 1, Loss: 0.9946056008338928\n",
      "Epoch 1, Loss: 1.1659549474716187\n",
      "Epoch 1, Loss: 0.8796322345733643\n",
      "Epoch 1, Loss: 0.8450119495391846\n",
      "Epoch 1, Loss: 0.9431067705154419\n",
      "Epoch 1, Loss: 1.0268938541412354\n",
      "Epoch 1, Loss: 1.0047473907470703\n",
      "Epoch 1, Loss: 1.3704111576080322\n",
      "Epoch 1, Loss: 0.9121803045272827\n",
      "Epoch 1, Loss: 0.7596670985221863\n",
      "Epoch 1, Loss: 1.1327364444732666\n",
      "Epoch 1, Loss: 1.238095998764038\n",
      "Epoch 1, Loss: 1.154577374458313\n",
      "Epoch 1, Loss: 0.8954938054084778\n",
      "Epoch 1, Loss: 0.9763913154602051\n",
      "Epoch 1, Loss: 0.9871254563331604\n",
      "Epoch 1, Loss: 0.9147140383720398\n",
      "Epoch 1, Loss: 0.8139171004295349\n",
      "Epoch 1, Loss: 1.0492266416549683\n",
      "Epoch 1, Loss: 1.0597928762435913\n",
      "Epoch 1, Loss: 1.1897366046905518\n",
      "Epoch 1, Loss: 0.849392294883728\n",
      "Epoch 1, Loss: 1.0196338891983032\n",
      "Epoch 1, Loss: 0.9823533296585083\n",
      "Epoch 1, Loss: 1.101658821105957\n",
      "Epoch 1, Loss: 0.8093107342720032\n",
      "Epoch 1, Loss: 0.9445672631263733\n",
      "Epoch 1, Loss: 0.9346525073051453\n",
      "Epoch 1, Loss: 1.1671514511108398\n",
      "Epoch 1, Loss: 1.045218825340271\n",
      "Epoch 1, Loss: 0.9274619817733765\n",
      "Epoch 1, Loss: 1.10305917263031\n",
      "Epoch 1, Loss: 1.087014079093933\n",
      "Epoch 1, Loss: 1.1780859231948853\n",
      "Epoch 1, Loss: 1.0612208843231201\n",
      "Epoch 1, Loss: 1.0423297882080078\n",
      "Epoch 1, Loss: 1.5959848165512085\n",
      "Epoch 1, Loss: 0.9949607849121094\n",
      "Epoch 1, Loss: 1.150686264038086\n",
      "Epoch 1, Loss: 0.9569053649902344\n",
      "Epoch 1, Loss: 0.9930681586265564\n",
      "Epoch 1, Loss: 1.4534598588943481\n",
      "Epoch 1, Loss: 1.1741782426834106\n",
      "Epoch 1, Loss: 0.9441710710525513\n",
      "Epoch 1, Loss: 0.9368664622306824\n",
      "Epoch 1, Loss: 1.1692078113555908\n",
      "Epoch 1, Loss: 1.0660510063171387\n",
      "Epoch 1, Loss: 0.9509541988372803\n",
      "Epoch 1, Loss: 1.07551109790802\n",
      "Epoch 1, Loss: 0.9280754923820496\n",
      "Epoch 1, Loss: 0.9435529112815857\n",
      "Epoch 1, Loss: 0.8846511244773865\n",
      "Epoch 1, Loss: 0.9596941471099854\n",
      "Epoch 1, Loss: 1.0651172399520874\n",
      "Epoch 1, Loss: 0.9213518500328064\n",
      "Epoch 1, Loss: 1.0632001161575317\n",
      "Epoch 1, Loss: 1.1478698253631592\n",
      "Epoch 1, Loss: 1.006717562675476\n",
      "Epoch 1, Loss: 0.9812520742416382\n",
      "Epoch 1, Loss: 0.8066680431365967\n",
      "Epoch 1, Loss: 1.1582802534103394\n",
      "Epoch 1, Loss: 1.1458739042282104\n",
      "Epoch 1, Loss: 1.1642953157424927\n",
      "Epoch 1, Loss: 0.9440428614616394\n",
      "Epoch 1, Loss: 1.161389708518982\n",
      "Epoch 1, Loss: 1.0503149032592773\n",
      "Epoch 1, Loss: 1.130324363708496\n",
      "Epoch 1, Loss: 1.0572240352630615\n",
      "Epoch 1, Loss: 0.9070033431053162\n",
      "Epoch 1, Loss: 0.8861949443817139\n",
      "Epoch 1, Loss: 0.8696891665458679\n",
      "Epoch 1, Loss: 0.9828922748565674\n",
      "Epoch 1, Loss: 0.9253910183906555\n",
      "Epoch 1, Loss: 0.696437418460846\n",
      "Epoch 1, Loss: 0.6186721920967102\n",
      "Epoch 1, Loss: 0.7480365037918091\n",
      "Epoch 1, Loss: 0.9419925212860107\n",
      "Epoch 1, Loss: 0.8700045943260193\n",
      "Epoch 1, Loss: 1.151721477508545\n",
      "Epoch 1, Loss: 1.6273730993270874\n",
      "Epoch 1, Loss: 1.3256198167800903\n",
      "Epoch 1, Loss: 0.8477040529251099\n",
      "Epoch 1, Loss: 1.0115545988082886\n",
      "Epoch 1, Loss: 1.1169476509094238\n",
      "Epoch 1, Loss: 0.9715325236320496\n",
      "Epoch 1, Loss: 0.9956400990486145\n",
      "Epoch 1, Loss: 0.8935346603393555\n",
      "Epoch 1, Loss: 0.9469609260559082\n",
      "Epoch 1, Loss: 0.9251986145973206\n",
      "Epoch 1, Loss: 1.2019208669662476\n",
      "Epoch 1, Loss: 0.958210825920105\n",
      "Epoch 1, Loss: 0.8915151953697205\n",
      "Epoch 1, Loss: 0.9279517531394958\n",
      "Epoch 1, Loss: 0.8079584836959839\n",
      "Epoch 1, Loss: 1.155625820159912\n",
      "Epoch 1, Loss: 1.1180025339126587\n",
      "Epoch 1, Loss: 0.9152162671089172\n",
      "Epoch 1, Loss: 1.0004918575286865\n",
      "Epoch 1, Loss: 0.9313377737998962\n",
      "Epoch 1, Loss: 0.9159203171730042\n",
      "Epoch 1, Loss: 1.088382363319397\n",
      "Epoch 1, Loss: 0.9335275292396545\n",
      "Epoch 1, Loss: 1.2791292667388916\n",
      "Epoch 1, Loss: 1.123215913772583\n",
      "Epoch 1, Loss: 0.7935099601745605\n",
      "Epoch 1, Loss: 1.1619200706481934\n",
      "Epoch 1, Loss: 1.149845004081726\n",
      "Epoch 1, Loss: 1.2250432968139648\n",
      "Epoch 1, Loss: 1.231956958770752\n",
      "Epoch 1, Loss: 1.2562899589538574\n",
      "Epoch 1, Loss: 1.2702479362487793\n",
      "Epoch 1, Loss: 1.1227785348892212\n",
      "Epoch 1, Loss: 1.1753934621810913\n",
      "Epoch 1, Loss: 1.050204873085022\n",
      "Epoch 1, Loss: 0.8669165372848511\n",
      "Epoch 1, Loss: 1.2651890516281128\n",
      "Epoch 1, Loss: 1.0122861862182617\n",
      "Epoch 1, Loss: 1.0688358545303345\n",
      "Epoch 1, Loss: 1.0609170198440552\n",
      "Epoch 1, Loss: 0.7830826640129089\n",
      "Epoch 1, Loss: 0.8219155073165894\n",
      "Epoch 1, Loss: 1.0363601446151733\n",
      "Epoch 1, Loss: 0.9462339282035828\n",
      "Epoch 1, Loss: 1.0699925422668457\n",
      "Epoch 1, Loss: 1.191946268081665\n",
      "Epoch 1, Loss: 0.8745441436767578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0745693445205688\n",
      "Epoch 1, Loss: 0.9548928141593933\n",
      "Epoch 1, Loss: 0.8847711682319641\n",
      "Epoch 1, Loss: 0.6692931056022644\n",
      "Epoch 1, Loss: 1.0216764211654663\n",
      "Epoch 1, Loss: 1.089709758758545\n",
      "Epoch 1, Loss: 0.8790271282196045\n",
      "Epoch 1, Loss: 0.9045357704162598\n",
      "Epoch 1, Loss: 1.060943603515625\n",
      "Epoch 1, Loss: 1.018239140510559\n",
      "Epoch 1, Loss: 1.182443618774414\n",
      "Epoch 1, Loss: 0.7284845113754272\n",
      "Epoch 1, Loss: 0.8001991510391235\n",
      "Epoch 1, Loss: 1.1180188655853271\n",
      "Epoch 1, Loss: 1.1720999479293823\n",
      "Epoch 1, Loss: 1.2311949729919434\n",
      "Epoch 1, Loss: 0.8016642928123474\n",
      "Epoch 1, Loss: 1.3805642127990723\n",
      "Epoch 1, Loss: 0.9212497472763062\n",
      "Epoch 1, Loss: 1.1573493480682373\n",
      "Epoch 1, Loss: 1.1153925657272339\n",
      "Epoch 1, Loss: 0.8781893849372864\n",
      "Epoch 1, Loss: 0.9925499558448792\n",
      "Epoch 1, Loss: 0.9872846007347107\n",
      "Epoch 1, Loss: 1.2269577980041504\n",
      "Epoch 1, Loss: 1.0368698835372925\n",
      "Epoch 1, Loss: 0.9110292792320251\n",
      "Epoch 1, Loss: 1.0320338010787964\n",
      "Epoch 1, Loss: 1.0306347608566284\n",
      "Epoch 1, Loss: 1.0124057531356812\n",
      "Epoch 1, Loss: 1.0644683837890625\n",
      "Epoch 1, Loss: 1.0824673175811768\n",
      "Epoch 1, Loss: 1.062399983406067\n",
      "Epoch 1, Loss: 1.020973563194275\n",
      "Epoch 1, Loss: 0.8474735021591187\n",
      "Epoch 1, Loss: 0.9420810341835022\n",
      "Epoch 1, Loss: 0.9430885910987854\n",
      "Epoch 1, Loss: 1.1134846210479736\n",
      "Epoch 1, Loss: 0.9376565217971802\n",
      "Epoch 1, Loss: 0.8670201897621155\n",
      "Epoch 1, Loss: 1.1227842569351196\n",
      "Epoch 1, Loss: 0.9474021196365356\n",
      "Epoch 1, Loss: 0.8176386952400208\n",
      "Epoch 1, Loss: 1.0351828336715698\n",
      "Epoch 1, Loss: 0.919071614742279\n",
      "Epoch 1, Loss: 1.3836610317230225\n",
      "Epoch 1, Loss: 1.1051430702209473\n",
      "Epoch 1, Loss: 1.0079807043075562\n",
      "Epoch 1, Loss: 1.0874022245407104\n",
      "Epoch 1, Loss: 0.9667839407920837\n",
      "Epoch 1, Loss: 0.9981423616409302\n",
      "Epoch 1, Loss: 0.7268547415733337\n",
      "Epoch 1, Loss: 1.0347980260849\n",
      "Epoch 1, Loss: 1.2153608798980713\n",
      "Epoch 1, Loss: 1.3875529766082764\n",
      "Epoch 1, Loss: 0.8455730080604553\n",
      "Epoch 1, Loss: 1.0563040971755981\n",
      "Epoch 1, Loss: 1.0690600872039795\n",
      "Epoch 1, Loss: 0.9617891907691956\n",
      "Epoch 1, Loss: 1.0977990627288818\n",
      "Epoch 1, Loss: 1.0659949779510498\n",
      "Epoch 1, Loss: 1.0024521350860596\n",
      "Epoch 1, Loss: 0.7456935048103333\n",
      "Epoch 1, Loss: 0.8411925435066223\n",
      "Epoch 1, Loss: 1.2746610641479492\n",
      "Epoch 1, Loss: 1.125403881072998\n",
      "Epoch 1, Loss: 0.9818804860115051\n",
      "Epoch 1, Loss: 1.0139333009719849\n",
      "Epoch 1, Loss: 1.0642818212509155\n",
      "Epoch 1, Loss: 0.972241997718811\n",
      "Epoch 1, Loss: 1.0838698148727417\n",
      "Epoch 1, Loss: 0.9402644038200378\n",
      "Epoch 1, Loss: 0.9574575424194336\n",
      "Epoch 1, Loss: 1.0091537237167358\n",
      "Epoch 1, Loss: 0.9346116781234741\n",
      "Epoch 1, Loss: 0.9641925692558289\n",
      "Epoch 1, Loss: 0.8021004796028137\n",
      "Epoch 1, Loss: 0.8908261656761169\n",
      "Epoch 1, Loss: 1.2444831132888794\n",
      "Epoch 1, Loss: 0.7421537041664124\n",
      "Epoch 1, Loss: 0.8282288908958435\n",
      "Epoch 1, Loss: 1.221277117729187\n",
      "Epoch 1, Loss: 0.9859634041786194\n",
      "Epoch 1, Loss: 0.9865166544914246\n",
      "Epoch 1, Loss: 0.8516855239868164\n",
      "Epoch 1, Loss: 0.8579767346382141\n",
      "Epoch 1, Loss: 0.9485583901405334\n",
      "Epoch 1, Loss: 0.9352262616157532\n",
      "Epoch 1, Loss: 1.1010652780532837\n",
      "Epoch 1, Loss: 1.0466381311416626\n",
      "Epoch 1, Loss: 0.9967225193977356\n",
      "Epoch 1, Loss: 0.8243392705917358\n",
      "Epoch 1, Loss: 1.2423162460327148\n",
      "Epoch 1, Loss: 0.7243859767913818\n",
      "Epoch 1, Loss: 0.9801923632621765\n",
      "Epoch 1, Loss: 1.0656225681304932\n",
      "Epoch 1, Loss: 0.818100094795227\n",
      "Epoch 1, Loss: 1.0922441482543945\n",
      "Epoch 1, Loss: 1.0601005554199219\n",
      "Epoch 1, Loss: 1.0790948867797852\n",
      "Epoch 1, Loss: 0.9234776496887207\n",
      "Epoch 1, Loss: 1.1953051090240479\n",
      "Epoch 1, Loss: 1.1604423522949219\n",
      "Epoch 1, Loss: 1.1020619869232178\n",
      "Epoch 1, Loss: 1.2280210256576538\n",
      "Epoch 1, Loss: 0.956887423992157\n",
      "Epoch 1, Loss: 1.0653022527694702\n",
      "Epoch 1, Loss: 1.010219931602478\n",
      "Epoch 1, Loss: 0.9974108338356018\n",
      "Epoch 1, Loss: 0.9399976134300232\n",
      "Epoch 1, Loss: 1.2139731645584106\n",
      "Epoch 1, Loss: 0.9133551120758057\n",
      "Epoch 1, Loss: 1.087738037109375\n",
      "Epoch 1, Loss: 0.9608535170555115\n",
      "Epoch 1, Loss: 1.055612564086914\n",
      "Epoch 1, Loss: 0.8637742400169373\n",
      "Epoch 1, Loss: 1.0620713233947754\n",
      "Epoch 1, Loss: 0.8297334909439087\n",
      "Epoch 1, Loss: 1.1295582056045532\n",
      "Epoch 1, Loss: 0.9362406134605408\n",
      "Epoch 1, Loss: 1.0136661529541016\n",
      "Epoch 1, Loss: 0.7435660362243652\n",
      "Epoch 1, Loss: 0.7717418074607849\n",
      "Epoch 1, Loss: 1.2266923189163208\n",
      "Epoch 1, Loss: 1.0879335403442383\n",
      "Epoch 1, Loss: 0.7975149750709534\n",
      "Epoch 1, Loss: 1.0024487972259521\n",
      "Epoch 1, Loss: 1.1286870241165161\n",
      "Epoch 1, Loss: 1.023998737335205\n",
      "Epoch 1, Loss: 1.0138792991638184\n",
      "Epoch 1, Loss: 0.895991861820221\n",
      "Epoch 1, Loss: 0.9767339825630188\n",
      "Epoch 1, Loss: 1.3754336833953857\n",
      "Epoch 1, Loss: 1.0837202072143555\n",
      "Epoch 1, Loss: 1.1572694778442383\n",
      "Epoch 1, Loss: 1.2701528072357178\n",
      "Epoch 1, Loss: 0.8603140711784363\n",
      "Epoch 1, Loss: 1.0811446905136108\n",
      "Epoch 1, Loss: 1.385360836982727\n",
      "Epoch 1, Loss: 1.2049064636230469\n",
      "Epoch 1, Loss: 1.1225526332855225\n",
      "Epoch 1, Loss: 1.126530647277832\n",
      "Epoch 1, Loss: 1.0556411743164062\n",
      "Epoch 1, Loss: 1.0012065172195435\n",
      "Epoch 1, Loss: 1.0894681215286255\n",
      "Epoch 1, Loss: 0.8896893262863159\n",
      "Epoch 1, Loss: 0.85548996925354\n",
      "Epoch 1, Loss: 1.2318291664123535\n",
      "Epoch 1, Loss: 1.1482994556427002\n",
      "Epoch 1, Loss: 1.1024495363235474\n",
      "Epoch 1, Loss: 1.0319162607192993\n",
      "Epoch 1, Loss: 0.8535585403442383\n",
      "Epoch 1, Loss: 1.0689442157745361\n",
      "Epoch 1, Loss: 1.1635812520980835\n",
      "Epoch 1, Loss: 0.8801782727241516\n",
      "Epoch 1, Loss: 1.0159543752670288\n",
      "Epoch 1, Loss: 0.8381037712097168\n",
      "Epoch 1, Loss: 1.213942289352417\n",
      "Epoch 1, Loss: 1.0799270868301392\n",
      "Epoch 1, Loss: 1.0158435106277466\n",
      "Epoch 1, Loss: 1.1271764039993286\n",
      "Epoch 1, Loss: 1.00735604763031\n",
      "Epoch 1, Loss: 1.2014696598052979\n",
      "Epoch 1, Loss: 1.0421878099441528\n",
      "Epoch 1, Loss: 0.8753353357315063\n",
      "Epoch 1, Loss: 0.9450246691703796\n",
      "Epoch 1, Loss: 1.0666073560714722\n",
      "Epoch 1, Loss: 0.906006932258606\n",
      "Epoch 1, Loss: 0.9182456135749817\n",
      "Epoch 1, Loss: 0.8964205980300903\n",
      "Epoch 1, Loss: 0.7787224054336548\n",
      "Epoch 1, Loss: 1.0150656700134277\n",
      "Epoch 1, Loss: 0.8430428504943848\n",
      "Epoch 1, Loss: 0.6741205453872681\n",
      "Epoch 1, Loss: 1.0231752395629883\n",
      "Epoch 1, Loss: 1.0346606969833374\n",
      "Epoch 1, Loss: 1.0118192434310913\n",
      "Epoch 1, Loss: 0.8917720317840576\n",
      "Epoch 1, Loss: 1.0276700258255005\n",
      "Epoch 1, Loss: 0.8590867519378662\n",
      "Epoch 1, Loss: 1.1552342176437378\n",
      "Epoch 1, Loss: 0.9352673888206482\n",
      "Epoch 1, Loss: 0.9074323177337646\n",
      "Epoch 1, Loss: 0.9855313301086426\n",
      "Epoch 1, Loss: 1.1541191339492798\n",
      "Epoch 1, Loss: 1.3239734172821045\n",
      "Epoch 1, Loss: 0.9792261719703674\n",
      "Epoch 1, Loss: 0.9343013763427734\n",
      "Epoch 1, Loss: 0.9350683689117432\n",
      "Epoch 1, Loss: 0.9096310138702393\n",
      "Epoch 1, Loss: 1.0570968389511108\n",
      "Epoch 1, Loss: 1.0836881399154663\n",
      "Epoch 1, Loss: 0.9373435974121094\n",
      "Epoch 1, Loss: 1.0330816507339478\n",
      "Epoch 1, Loss: 0.8909807205200195\n",
      "Epoch 1, Loss: 1.2299132347106934\n",
      "Epoch 1, Loss: 1.138689637184143\n",
      "Epoch 1, Loss: 1.0815541744232178\n",
      "Epoch 1, Loss: 0.6935499310493469\n",
      "Epoch 1, Loss: 0.9601489901542664\n",
      "Epoch 1, Loss: 0.8207938075065613\n",
      "Epoch 1, Loss: 1.015771746635437\n",
      "Epoch 1, Loss: 0.923062801361084\n",
      "Epoch 1, Loss: 0.9267023801803589\n",
      "Epoch 1, Loss: 1.3864774703979492\n",
      "Epoch 1, Loss: 0.794160783290863\n",
      "Epoch 1, Loss: 1.1460398435592651\n",
      "Epoch 1, Loss: 1.3689454793930054\n",
      "Epoch 1, Loss: 0.922569990158081\n",
      "Epoch 1, Loss: 0.9758641719818115\n",
      "Epoch 1, Loss: 1.0287846326828003\n",
      "Epoch 1, Loss: 0.9524807929992676\n",
      "Epoch 1, Loss: 0.8434620499610901\n",
      "Epoch 1, Loss: 1.1033246517181396\n",
      "Epoch 1, Loss: 0.8652649521827698\n",
      "Epoch 1, Loss: 1.4355350732803345\n",
      "Epoch 1, Loss: 0.916452944278717\n",
      "Epoch 1, Loss: 1.3169207572937012\n",
      "Epoch 1, Loss: 1.0720272064208984\n",
      "Epoch 1, Loss: 0.9562147259712219\n",
      "Epoch 1, Loss: 1.1066879034042358\n",
      "Epoch 1, Loss: 1.2047665119171143\n",
      "Epoch 1, Loss: 0.9785839915275574\n",
      "Epoch 1, Loss: 1.2588857412338257\n",
      "Epoch 1, Loss: 1.0512747764587402\n",
      "Epoch 1, Loss: 0.8714532256126404\n",
      "Epoch 1, Loss: 0.8988115787506104\n",
      "Epoch 1, Loss: 0.8599988222122192\n",
      "Epoch 1, Loss: 0.9260382056236267\n",
      "Epoch 1, Loss: 0.9057861566543579\n",
      "Epoch 1, Loss: 0.8354373574256897\n",
      "Epoch 1, Loss: 0.984913170337677\n",
      "Epoch 1, Loss: 0.9517360329627991\n",
      "Epoch 1, Loss: 1.0365386009216309\n",
      "Epoch 1, Loss: 0.8789494633674622\n",
      "Epoch 1, Loss: 0.9569032192230225\n",
      "Epoch 1, Loss: 1.1232572793960571\n",
      "Epoch 1, Loss: 1.0135226249694824\n",
      "Epoch 1, Loss: 0.8248305916786194\n",
      "Epoch 1, Loss: 0.7796619534492493\n",
      "Epoch 1, Loss: 1.2170056104660034\n",
      "Epoch 1, Loss: 0.930755615234375\n",
      "Epoch 1, Loss: 1.0214157104492188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.9888074398040771\n",
      "Epoch 1, Loss: 0.8259889483451843\n",
      "Epoch 1, Loss: 0.843654453754425\n",
      "Epoch 1, Loss: 1.0074650049209595\n",
      "Epoch 1, Loss: 0.958469569683075\n",
      "Epoch 1, Loss: 0.972416877746582\n",
      "Epoch 1, Loss: 1.070834755897522\n",
      "Epoch 1, Loss: 0.9505323171615601\n",
      "Epoch 1, Loss: 1.1050238609313965\n",
      "Epoch 1, Loss: 0.7680666446685791\n",
      "Epoch 1, Loss: 1.1507292985916138\n",
      "Epoch 1, Loss: 0.9686877131462097\n",
      "Epoch 1, Loss: 0.9584017992019653\n",
      "Epoch 1, Loss: 1.2455490827560425\n",
      "Epoch 1, Loss: 1.0088424682617188\n",
      "Epoch 1, Loss: 1.0003879070281982\n",
      "Epoch 1, Loss: 0.9307259321212769\n",
      "Epoch 1, Loss: 0.9016596078872681\n",
      "Epoch 1, Loss: 1.1326358318328857\n",
      "Epoch 1, Loss: 1.0510433912277222\n",
      "Epoch 1, Loss: 0.8966044187545776\n",
      "Epoch 1, Loss: 0.977003276348114\n",
      "Epoch 1, Loss: 1.4683992862701416\n",
      "Epoch 1, Loss: 1.1058359146118164\n",
      "Epoch 1, Loss: 0.8870081305503845\n",
      "Epoch 1, Loss: 0.9649162292480469\n",
      "Epoch 1, Loss: 0.9418430924415588\n",
      "Epoch 1, Loss: 1.0651559829711914\n",
      "Epoch 1, Loss: 1.1920582056045532\n",
      "Epoch 1, Loss: 1.1637002229690552\n",
      "Epoch 1, Loss: 0.979202151298523\n",
      "Epoch 1, Loss: 0.9291625022888184\n",
      "Epoch 1, Loss: 1.098669409751892\n",
      "Epoch 1, Loss: 1.205510139465332\n",
      "Epoch 1, Loss: 0.8551166653633118\n",
      "Epoch 1, Loss: 1.0643316507339478\n",
      "Epoch 1, Loss: 1.0508215427398682\n",
      "Epoch 1, Loss: 0.9856897592544556\n",
      "Epoch 1, Loss: 1.001724362373352\n",
      "Epoch 1, Loss: 0.9792658090591431\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "# for epoch in range(3):  # Adjust number of epochs as needed\n",
    "#     for batch in train_dataloader:\n",
    "#         input_ids = batch[\"input_ids\"].to(device)\n",
    "#         attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#         labels = batch[\"labels\"].to(device)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(\n",
    "#             input_ids=input_ids,\n",
    "#             attention_mask=attention_mask,\n",
    "#             labels=labels,\n",
    "#         )\n",
    "#         loss = outputs.loss\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n",
    "\n",
    "for epoch in range(1):  # Adjust number of epochs as needed\n",
    "    for batch in train_dataloader:\n",
    "        # Convert each sequence in the batch to tensors and move them to device\n",
    "        input_ids = torch.tensor([item for sublist in batch[\"input_ids\"] for item in sublist]).to(device)\n",
    "        attention_mask = torch.tensor([item for sublist in batch[\"attention_mask\"] for item in sublist]).to(device)\n",
    "        labels = torch.tensor([item for sublist in batch[\"labels\"] for item in sublist]).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(\n",
    "            input_ids=input_ids.unsqueeze(0),  \n",
    "            attention_mask=attention_mask.unsqueeze(0),  \n",
    "            labels=labels.unsqueeze(0),  \n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994ad0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "model.save_pretrained(\"model_weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
